## Dataquest guided projects
Dataquest's guided projects are an interactive component of their online learning platform. These projects offer a hands-on, real-world experience that complements the theoretical knowledge gained on the course. This involves work with real datasets, writing code, and solving data-related problems.

### [Project 1 - Prison Break](https://github.com/rashad-malik/Dataquest-Projects/tree/main/Project%201:%20Prison%20Break)
WIP

### [Project 2 - Profitable App Profiles for the App Store and Google Play Markets](https://github.com/rashad-malik/Dataquest-Projects/tree/main/Project%202:%20Profitable%20App%20Profiles)
WIP

### [Project 3 - Exploring Hacker News Posts](https://github.com/rashad-malik/Dataquest-Projects/blob/main/Project%203%3A%20Exploring%20Hacker%20News%20Posts/Project_3.ipynb)
In this project, I worked with a dataset of submissions to popular technology site [Hacker News](https://news.ycombinator.com/). This project brought the following skills together for some real-world practice:
- How to work with strings.
- Object-oriented programming.
- Dates and times.

### [Project 4 - Exploring eBay Car Sales Data](https://github.com/rashad-malik/Dataquest-Projects/tree/main/Project%204%3A%20Exploring%20eBay%20Car%20Sales%20Data)
WIP

### [Project 5 - Finding Heavy Traffic Indicators on I-94](https://github.com/rashad-malik/Dataquest-Projects/tree/main/Project%205%3A%20Finding%20Heavy%20Traffic%20Indicators%20on%20I-94)
WIP

### [Project 6 - Storytelling Data Visualisation on Exchange Rates](https://github.com/rashad-malik/Dataquest-Projects/blob/main/Project%206%3A%20Storytelling%20Data%20Visualisation%20on%20Exchange%20Rates/Project_6.ipynb)
The following project focused on explanatory data visualisation. The dataset used describes the Euro (€) daily exchange rates between 1999 and 2021, hosted on [Kaggle](https://www.kaggle.com/datasets/lsind18/euro-exchange-daily-rates-19992020) by [Daria Chemkaeva](https://www.kaggle.com/lsind18). Key skills demonstrated in this project include the following:
- Using information design principles (familiarity and maximising the data-ink ratio) to create better graphs for an audience.
- How to create storytelling data visualisations using Matplotlib.
- How to create visual patterns using Gestalt principles.
- How to guide the audience's attention with pre-attentive attributes.
- How to use Matplotlib built-in styles — with a case study on the FiveThirtyEight style.

![Coded graph for Project 6](/Rashad_Portfolio/docs/assets/project6_graph.png)

### [Project 7 -  Clean and Analyse Employee Exit Surveys](https://github.com/rashad-malik/Dataquest-Projects/blob/main/Project%207%3A%20Clean%20and%20Analyse%20Employee%20Exit%20Surveys/Project_7.ipynb)
In this project, I worked with exit surveys from employees of the [Department of Education, Training and Employment (DETE)](https://en.wikipedia.org/wiki/Department_of_Education_(Queensland)) and the Technical and Further Education (TAFE) institute in Queensland, Australia. The dataset used is the [DETE exit survey data](https://data.gov.au/dataset/ds-qld-fe96ff30-d157-4a81-851d-215f2a0fe26d/details?q=exit%20survey). I played the role of a data analyst and pretended our stakeholders wanted to know the following:
- Are employees who only worked for the institutes for a short period of time resigning due to some kind of dissatisfaction? What about employees who have been there longer?
- Are younger employees resigning due to some kind of dissatisfaction? What about older employees?

Key skills used in this project include:
- Vectorised string methods to clean string columns.
- The apply(), map(), and applymap() methods to transform data.
- The fillna(), dropna(), and drop() methods to drop missing or unnecessary values.
- The melt() function to reshape data.
- The concat() and merge() functions to combine data.

### [Project 8 - Analysing CIA Factbook Data Using SQL](https://github.com/rashad-malik/Dataquest-Projects/blob/main/Project%208%3A%20Analysing%20CIA%20Factbook%20Data%20Using%20SQL/Project_8.ipynb)
For this project, I worked with data from the [CIA World Factbook](https://www.cia.gov/the-world-factbook/). I used SQL in Jupyter Notebook to analyse data from this database. Some of the key skills demonstrated include:
- Investigating tables with SQL.
- Outputing summary statistics (maximum, minumum, growth values).
- Calculating means.
- Finding elements within the table that meet a specific criteria.

### [Project 9 - Investigating Fandango Movie Ratings](https://github.com/rashad-malik/Dataquest-Projects/blob/main/Project%209%3A%20Investigating%20Fandango%20Movie%20Ratings/Project_9.ipynb)
In this project, I analysed recent movie ratings data to determine whether there has been any change in Fandango's rating system after Walt Hickey's 2015 analysis. The two datasets that I used for this investigation are as follows:
- [Walt Hickey's dataset](https://github.com/fivethirtyeight/data/tree/master/fandango) for ratings up to 2015.
- [Dataquest's dataset](https://github.com/mircealex/Movie_ratings_2016_17) for ratings in 2016 and 2017.

This project demonstrates the use of statistical analysis in Python, with a focus on sampling, variables, scales of measurement, and frequency distributions.

![Coded graph for Project 9](/Rashad_Portfolio/docs/assets/project9_graph.png)

### [Project 10 - Finding the Best Markets to Advertise In](https://github.com/rashad-malik/Dataquest-Projects/blob/main/Project%2010%3A%20Finding%20the%20Best%20Markets%20to%20Advertise%20In/Project_10.ipynb)
Let's assume that I'm working for an an e-learning company that offers courses on programming. Most of the courses are on web and mobile development, but also cover many other domains, like data science, game development, etc. The company wants to promote the product invest some money in advertisement. My goal in this project is to find out the two best markets to advertise our product in. The key skills demonstrated in this project include:
- How to summarise distributions using the mean, the median, and the mode.
- How to measure the variability of a distribution using the range, the mean absolute deviation, the variance, and the standard deviation.
- How to locate any value in a distribution using z-scores.

![Coded graph for Project 10](/Rashad_Portfolio/docs/assets/project10_graph.png)

### [Project 11 - Mobile App for Lottery Addiction](https://github.com/rashad-malik/Dataquest-Projects/blob/main/Project%2011%3A%20Mobile%20App%20for%20Lottery%20Addiction/Project_11.ipynb)
A medical institute that aims to prevent and treat gambling addictions wants to build a dedicated mobile app to help lottery addicts better estimate their chances of winning. The institute has a team of engineers that will build the app, but they need us to create the logical core of the app and calculate probabilities. For the first version of the app, they want us to focus on the [6/49 lottery](https://en.wikipedia.org/wiki/Lotto_6/49) and build functions that enable users to answer questions like:
- What is the probability of winning the big prize with a single ticket?
- What is the probability of winning the big prize if we play 40 different tickets (or any other number)?
- What is the probability of having at least five (or four, or three, or two) winning numbers on a single ticket?

The institute also wants us to consider historical data coming from the national 6/49 lottery game in Canada. The [dataset](https://www.kaggle.com/datascienceai/lottery-dataset) has data for 3,665 drawings, dating from 1982 to 2018. Key skills demonstrated in this project include:
- How to calculate theoretical and empirical probabilities.
- How to use probability rules to solve probability problems.
- How to use combinations and permutations.

### [Project 12 - Building a Spam Filter with Naive Bayes](https://github.com/rashad-malik/Dataquest-Projects/tree/main/Project%2012:%20Building%20a%20Spam%20Filter%20with%20Naive%20Bayes)
WIP

### [Project 13 - Winning Jeopardy](https://github.com/rashad-malik/Dataquest-Projects/blob/main/Project%2013%3A%20Winning%20Jeopardy/Project_13.ipynb)
In this project, I worked with a dataset of Jeopardy questions to figure out some patterns in the questions that could help me win. The dataset is named jeopardy.csv, and contains 20000 rows from the beginning of a full dataset of Jeopardy questions, which can be downloaded from [this reddit post](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/).
Key skills shown in this project include:
- Significance testing.
- Chi-squared tests and multi-category chi-squared tests.
